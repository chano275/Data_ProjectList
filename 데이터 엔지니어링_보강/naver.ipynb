{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda00bc8-2229-49bf-b1c4-0e1c4f236547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1. 관련 패키지 및 모듈 불러오기\n",
    "from selenium import webdriver\n",
    "from  selenium.webdriver.common.by  import  By\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# step2. 네이버 뉴스 댓글정보 수집 함수\n",
    "def get_naver_news_comments(url, wait_time=5, delay_time=0.1):\n",
    "\n",
    "    # 크롬 드라이버로 해당 url에 접속\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # (크롬)드라이버가 요소를 찾는데에 최대 wait_time 초까지 기다림 (함수 사용 시 설정 가능하며 기본값은 5초)\n",
    "    driver.implicitly_wait(wait_time)\n",
    "\n",
    "    # 인자로 입력받은 url 주소를 가져와서 접속\n",
    "    driver.get(url)\n",
    "\n",
    "    # 더보기가 안뜰 때 까지 계속 클릭 (모든 댓글의 html을 얻기 위함)\n",
    "    while True:\n",
    "\n",
    "        # 예외처리 구문 - 더보기 광클하다가 없어서 에러 뜨면 while문을 나감(break)\n",
    "        try:\n",
    "            more  =  driver.find_element(By.CLASS_NAME,  'u_cbox_btn_more')\n",
    "            more.click()\n",
    "            time.sleep(delay_time)\n",
    "\n",
    "        except:\n",
    "            break\n",
    "\n",
    "    # 본격적인 크롤링 타임\n",
    "\n",
    "    # selenium으로 페이지 전체의 html 문서 받기\n",
    "    html = driver.page_source\n",
    "\n",
    "    # 위에서 받은 html 문서를 bs4 패키지로 parsing\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # 1)작성자\n",
    "    nicknames = soup.select('span.u_cbox_nick')\n",
    "    list_nicknames = [nickname.text for nickname in nicknames]\n",
    "\n",
    "    # 2)댓글 시간\n",
    "    datetimes = soup.select('span.u_cbox_date')\n",
    "    list_datetimes = [datetime.text for datetime in datetimes]\n",
    "\n",
    "    # 3)댓글 내용\n",
    "    contents = soup.select('span.u_cbox_contents') \n",
    "    list_contents = [content.text for content in contents]\n",
    "\n",
    "\n",
    "    # 4)작성자, 댓글 시간, 내용을 셋트로 취합\n",
    "    list_sum = list(zip(list_nicknames,list_datetimes,list_contents))\n",
    "\n",
    "    # 드라이버 종료\n",
    "    driver.quit()\n",
    "\n",
    "    # 함수를 종료하며 list_sum을 결과물로 제출\n",
    "    return list_sum\n",
    "\n",
    "# step3. 실제 함수 실행 및 엑셀로 저장\n",
    "if __name__ == '__main__': # 설명하자면 매우 길어져서 그냥 이렇게 사용하는 것을 권장\n",
    "\n",
    "    # 원하는 기사 url 입력\n",
    "    url = '댓글 열어놓은 기사의 뉴스 링크 삽입'\n",
    "\n",
    "    # 함수 실행\n",
    "    comments = get_naver_news_comments(url)\n",
    "\n",
    "    # 엑셀의 첫줄에 들어갈 컬럼명\n",
    "    col = ['작성자','시간','내용']\n",
    "\n",
    "    # pandas 데이터 프레임 형태로 가공\n",
    "    df = pd.DataFrame(comments, columns=col)\n",
    "\n",
    "    # 데이터 프레임을 엑셀로 저장 (파일명은 'news.xlsx', 시트명은 '뉴스 기사 제목')\n",
    "    df.to_excel('news.xlsx', sheet_name='뉴스 기사 제목')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069292d-f8b3-4afe-91b8-9cdcb762ffd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
